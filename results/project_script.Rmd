---
title: "Project outline"
output: html_notebook
---

# Instructions
This script is written for a test data set and can be run from start (QC preprocessing) to finish (Shannon entropy calculation). The test data set is generated in the data_acquisition.Rmd script and consist of a pair-end read for WTZIKV P0. The script is written so that it is run with the data directory as its working directory.

# QC Preprocessing
- **Original study:** Trimmomatic v0.22
- **Reproduction:** Trimmomatic v0.39

The trimming and quality control is done by using the software Trimmomatic. The version in the article is v0.22, we will operate on the current release v0.39. Although not a part of the original study, we will download the fastQC software for simple data visualization before and after trimming. Trim to minimal 35 bases and 35 quality scor as per instructed in original study.

```{bash}
# Initiate conda
source ~/.bashrc

# create new conda environment
conda create --name project

# activate conda environment
conda activate project

# Check current packages
conda list

# Install packages
conda install -c bioconda trimmomatic
conda install -c bioconda fastqc
```

Run fastQC software to inspect data. This will generate a .fastqc.zip file and a .html file which can be opened in a browser through Rstudio. This will show basic statistics for the read, including its average quality score across reads.
```{bash}
fastqc test_data/test_ERR4013290_1.fastq
```

Trimming and quality control may now be performed using Trimmomatic v0.39. Make new QC directory to facilitate trimmomatic output.
```{bash}
mkdir test_data/QC_test_data

trimmomatic PE -threads 4 test_ERR4013290_1.fastq test_ERR4013290_2.fastq  \
QC_test_data/test_ERR4013290_1.trimmed.fastq QC_test_data/test_ERR4013290_1un.trimmed.fastq \
QC_test_data/test_ERR4013290_2.trimmed.fastq QC_test_data/test_ERR4013290_2un.trimmed.fastq \
TRAILING:35 MINLEN:35
```

Optional: run fastQC again to view the trimmed data.
```{bash}
fastqc test_data/QC_test_data/test_ERR4013290_1.trimmed.fastq
```

# *de novo* assembly
- **Original study:** ABySS v1.3.7
- **Reproduction:** ABySS v2.2.5

ABySS is an assembler intended for short read data, such as the data generated by Illumina machines. Here the latest version (ABySS v) is used with a k-mere length of 30 to assemble *de novo* consensus sequences from the quality controlled pair-end reads. Note: in the original study ABySS v1.3.7 with a range of k values from 20 to 40 was used to find a optimal k-mere length.
```{bash}
conda install -c bioconda abyss
```

Run ABySS on the quality trimmed data. Make new directory to facilitate the big output from ABySS. ABySS can be run with either only the remaining pairs that survived the trimming or both the pairs and the remaining single reads. The last option does not generate a contigs.fa file and is therefore in some way erroneous.
```{bash}
mkdir test_data/QC_test_data/abyss_pe
abyss-pe name=WTZIKA k=30 in="test_data/QC_test_data/test_ERR4013290_1.trimmed.fastq 
                              test_data/QC_test_data/test_ERR4013290_2.trimmed.fastq" 
                              
# Move files to folder
mv test_data/QC_test_data/WTZIKA* test_data/QC_test_data/abyss_pe
mv test_data/QC_test_data/coverage* test_data/QC_test_data/abyss_pe

# Alternitavely: also include the single reads "un paired", this is erroneous
mkdir test_data/QC_test_data/abyss_pe_se

abyss-pe name=WTZIKA k=30 pe="test_data/QC_test_data/test_ERR4013290_1.trimmed.fastq 
                              test_data/QC_test_data/test_ERR4013290_2.trimmed.fastq" \                                                                     se="test_data/QC_test_data/test_ERR4013290_1un.trimmed.fastq       
                              test_data/QC_test_data/test_ERR4013290_2un.trimmed.fastq" 
# Move files to folder
mv test_data/QC_test_data/WTZIKA* test_data/QC_test_data/abyss_pe_se
mv test_data/QC_test_data/coverage* test_data/QC_test_data/abyss_pe_se
```

The output from the assembly is not sufficient for aligning since it does not consist of a single string (a genome). Therefore, the *de novo* sequences are not used further. Moving directly from here to Alignment with the *de novo* sequences replaced by a reference genome instead for the wild type strain.

# SKIPPED: Disassembly BAM files
- **Original study:** SamToFastq.jar and SAMtools
This step is only used if the ABySS software runs successfully. Therefore, this is skipped in the reproduction.

# Alignment
- **Original study:** Bowtie2 v2.2.4
- **Reproduction:** Bowtie2 v2.4.2

A full genome for WT ZIKV, strain FSS13025, is downloaded from GenBank (https://www.ncbi.nlm.nih.gov/nuccore/MH158236.1) to be used as reference sequence for alignment. This is done instead of using the failed *de novo* sequence generated by ABySS. The deviations should in theory be minor but point mutations may well be present in already in the P0 WT ZIKV sequenced.

For alignment Bowtie2 is used with specified local alignment mode and the very sensitive default setting consisting of Qphred of 20, max number of mismatch of 0, length of seed substring 20, and interval between seed substrings S,1,0.5 to apply a stringent alignment, as per instructed in original study. 

Bowtie2 uses a different version of python than the one used by trimmomatic, therefore, another conda environment is used for the following downstream analysis.

```{bash}
conda deactivate

# Create new environment
conda create --name project_downstream

conda activate project_downstream

# Install Bowtie2
conda install bowtie2
```

Make new directories to facilitate bowtie alignment as well as the generated bowtie index.
```{bash}
mkdir test_data/QC_test_data/bowtie_index
mkdir test_data/QC_test_data/alignment

# Build index for reference genome
bowtie2-build -f WTZIKV_FSS13025_reference.fasta test_data/QC_test_data/bowtie_index/WTZIKV
```

Run bowtie2 on the quality trimmed data.
```{bash}
# Run bowtie2 on both paired trimmed reads (-1 and -2) and on unpaired trimmed reads (-U)
bowtie2 --very-sensitive-local -x \
test_data/QC_test_data/bowtie_index/WTZIKV \
-1 test_data/QC_test_data/test_ERR4013290_1.trimmed.fastq \
-2 test_data/QC_test_data/test_ERR4013290_2.trimmed.fastq \
-U test_data/QC_test_data/test_ERR4013290_1un.trimmed.fastq, test_data/QC_test_data/test_ERR4013290_2un.trimmed.fastq \
-S test_data/QC_test_data/alignment/WTZKVIP0.sam 

```


# Compress SAM file and sort by coordinate
- **Original study:** SAMtools v1.1
- **Original study:** Picard-tools v1.128
- **Reproduction:** SAMtools v1.11
- **Reproduction:** Picard-tools v2.18.7

Install packages using conda. These are neccessary to convert the alignment .sam file from bowtie2 to a binary format (.bam) and to sort the .bam file by coordinate in the genome. This in turn is neccessary in order to find duplicates from the PCR amplification later and for calling SNPs. 
```{bash}
conda install -c bioconda samtools
conda install -c bioconda picard
```

Convert alignment .sam file to binary .bam format.
```{bash}
# Convert using samtools view
samtools view -S -b test_data/QC_test_data/alignment/WTZKVIP0.sam > test_data/QC_test_data/alignment/WTZKVIP0.bam
```

Sort the .bam file by coordinate and view it by converting to .sam format using samtools. 
```{bash}
# Run picard on .bam file
picard SortSam \
      I=test_data/QC_test_data/alignment/WTZKVIP0.bam \
      O=test_data/QC_test_data/alignment/WTZKVIP0_sorted.bam \
      SORT_ORDER=coordinate
      
# View the sorted .bam file
samtools view test_data/QC_test_data/alignment/WTZKVIP0_sorted.bam | less -S
```

# Remove PCR duplicates
The next step is to remove the PCR duplicates from the amplification step before sequencing. This is done also using Picard with the function MarkDuplicates on the sorted .bam file. Choose the setting REMOVE_DUPLICATES to actually remove them, otherwise they will only be tagged. View the data again with samtools.
```{bash}
# Remove duplicates
picard MarkDuplicates \
      I=test_data/QC_test_data/alignment/WTZKVIP0_sorted.bam \
      O=test_data/QC_test_data/alignment/WTZKVIP0_sorted_removed_duplicates.bam \
      M=test_data/QC_test_data/alignment/WTZKVIP0_sorted_removed_dup_metrics.txt \
      REMOVE_DUPLICATES=true
      
# View the data
samtools view test_data/QC_test_data/alignment/WTZKVIP0_sorted_removed_duplicates.bam | less -S
```

# Variant detection
- **Original study:** V-phaser2 v2.0
- **Reproduciton:** V-phaser2 v2.0

This will aim to find all SNP:s present in the data. The software used is called V-phaser2 and finds potential SNP:s and their corresponding p-values. The p-values are corrected for FDR directly by the software.
```{bash}
# Make a new directory for storing the Vphaser output
mkdir variant_calling

# Install Vphaser2
conda install -c bioconda vphaser2
```

Run V-phaser2 on the duplictate removed sorted .bam file.
```{bash}
# Run Vphaser2 on the duplicate removed, sorted file
vphaser2 -i test_data/QC_test_data/alignment/WTZKVIP0_sorted_removed_duplicates.bam \
          -o test_data/QC_test-data/alignment/variant_calling
```

# Shannon entropy
- **Original study:** deepSNV v1.16.0
- **Reproduction:** deepSNV v1.99.3

The Shannon entropy is calculated based on relative frequencies of nucleotides on each position in the genome. The frequencies are calculated using two functions in the R-package deepSNV, namely bam2R and RF. bam2R converts the duplicate removed, sorted .bam file to a count matrix with position in genome as rows and nucleotide/indel/quality as columns. The count matrix can be used inside the function RF to calculate each position's relative nucleotide frequency.

Install deepSNV into R. Note: The R version of the reproduction is 3.6 and does not support the current release of Bioconductor, therefore, an older version is installed.
```{r}
if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
BiocManager::install(version = "3.10")

# Install deepSNV
BiocManager::install("deepSNV")
```

Run bam2R to produce count matrix. Run from start position 107 to position 10700 and quality threshold 30, as per instructed by original study.
```{r}
library(deepSNV)

# Define path to file
path_to_file = "home/student12/project/data/test_data/QC_test_data/alignment/"

# No chromosome available, pass empty string as argument
counts = bam2R(paste0(path_to_file, "WTZKVIP0_sorted_removed_duplicates.bam"), chr = "", start = 107, stop = 10700, q = 30)

```

Run RF to extract relative frequencies from count matrix. Extract the columns containing nucleotide information.
```{r}
# Extract columns with nucleotides (exclude N/n, INS/ins, DEL/del and QUAL/qual)
nucleotide_counts = counts[,c(1:5,12:16)]

# Run RF
relative_frequencies = RF(nucleotide_counts)
```

Calculate Shannon entropy from relative frequencies for each position in the genome. Note: original study only use the five first columns to calculate the entropy, not the last five. 
```{r}
# Function supplied by supplementary material of original study
new_entropy = function(x){
  x[1:5]
  new_entropy = -sum(x*log(x), na.rm = TRUE)
  
  return(new_entropy)}

# Convert to data.frame for visualization
shannon_entropy = as.data.frame(apply(relative_frequencies, 1, new_entropy))
```







# Loading data
## Load data into R
```{r}
library(tidyverse)
# set root directory
root = "/home/student12/project/"

# Load the metadata, use paste0() to concatenate two strings
sample_metadata <- read_tsv(paste0(root,"data/sample_metadata.txt"))

# inspect metadata
head(sample_metadata)
```

# QC Preprocessing
Trim to minimal 35 bases and 35 quality score: **Trimmomatic v0.22**

## Packages and software
The trimming and quality control is done by using the software Trimmomatic. The version in the article is v0.22, we will operate on the current release v0.39. Although not a part of the original study, we will download the fastQC software for simple data visualization before and after trimming.

```{bash}
# Initiate conda
source ~/.bashrc

# Check current packages
conda list

# activate conda environment
conda activate project

# The project environment is a clone of the sequencing conda environment containing:
# conda install samtools bowtie2 breseq abyss bcftools wgsim emboss tree

conda install -c bioconda trimmomatic

# Not mandatory: install fastqc to view fastq files in browser
conda install -c bioconda fastqc

```

Run fastQC software to inspect data. This will generate a .fastqc.zip file and a .html file which can be opened in a browser through Rstudio. This will show basic statistics for the read, including its average quality score across reads.

```{bash}
fastqc test_data/TEST_FILE
```


## Trimming and quality control
Trimming and quality control may now be performed using Trimmomatic v0.39. 

```{bash}
mkdir QC_test_data

trimmomatic PE -threads 4 test_ERR4013290_1.fastq test_ERR4013290_2.fastq  \
              QC_test_data/test_ERR4013290_1.trimmed.fastq                         QC_test_data/test_ERR4013290_1un.trimmed.fastq \
              QC_test_data/test_ERR4013290_2.trimmed.fastq QC_test_data/test_ERR4013290_2un.trimmed.fastq \
              TRAILING:35 MINLEN:35

##### Analysis for 10D_P0

mkdir all_data/QC_all_data/10D_P0

trimmomatic PE -threads 4 ERR4013291_1.fastq ERR4013291_2.fastq  \
              QC_all_data/10D_P0/ERR4013291_1.trimmed.fastq                         QC_all_data/10D_P0/ERR4013291_1un.trimmed.fastq \
              QC_all_data/10D_P0/ERR4013291_2.trimmed.fastq QC_all_data/10D_P0/ERR4013291_2un.trimmed.fastq \
              TRAILING:35 MINLEN:35
              
```

# de novo assembly
**ABySS v1.3.7**
ABySS v1.3.7 with k values from 20 to 40 was used for de novo assembly of pair-end reads and de novo consensus sequences generated.

```{bash}
# Install ABySS using conda
conda install -c bioconda abyss
```

Run ABySS
```{bash}
mkdir QC_all_data/10D_P0/abyss_pe

abyss-pe name=WTZIKA k=20 in="ERR4013291_1.trimmed.fastq 
                              ERR4013291_2.trimmed.fastq" 
                              
# Move files to folder
mv WTZIKA* abyss_pe
mv coverage* abyss_pe

mkdir abyss_pe_se

abyss-pe name=WTZIKA k=20 pe="ERR4013291_1.trimmed.fastq ERR4013291_2.trimmed.fastq"                              se="ERR4013291_1un.trimmed.fastq ERR4013291_2un.trimmed.fastq" 
mv WTZIKA* abyss_pe_se
mv coverage* abyss_pe_se
```

<<<<<<< HEAD
=======
Choosing to skip the de novo sequences generated by ABySS due to strange output. Moving directly from here to Alignment with reference genome instead.

# SKIPPED: Disassembly BAM files
**SamToFastq.jar** and **SAMtools**


>>>>>>> 403c3033675fa61f663d2488fb5e39b8eea8fbd5
# Alignment
(reference, de novo concensus) with very sensitive local alignment:
**Bowtie2 v2.2.4**
```{bash}
conda deactivate
# Activate sequencing environment
conda activate sequencing
# Make new directoies to facilitate bowtie2 output
mkdir /home/student12/project/data/all_data/QC_all_data/10D_P0/bowtie_index
mkdir /home/student12/project/data/all_data/QC_all_data/10D_P0/alignment
# Build index for reference genome
bowtie2-build -f WTZIKV_FSS13025_reference.fasta all_data/QC_all_data/10D_P0/bowtie_index/WTZIKV

bowtie2 --very-sensitive-local -x QC_all_data/10D_P0/bowtie_index/WTZIKV -1 QC_all_data/10D_P0/ERR4013291_1.trimmed.fastq -2 QC_all_data/10D_P0/ERR4013291_2.trimmed.fastq -U QC_all_data/10D_P0/ERR4013291_1un.trimmed.fastq, QC_all_data/10D_P0/ERR4013291_2un.trimmed.fastq -S QC_all_data/10D_P0/alignment/10D_P0.sam 

samtools view -S -b QC_all_data/10D_P0/alignment/10D_P0.sam > QC_all_data/10D_P0/alignment/10D_P0.bam
```

<<<<<<< HEAD
```{bash}
# Install Picard
conda install -c bioconda picard
=======
A full genome for WT ZIKV FSS13025 was downloaded from GenBank (https://www.ncbi.nlm.nih.gov/nuccore/MH158236.1) to be used as reference sequence for alignment. This was done instead of using the failed de novo sequence generated by ABySS, as per the study. The deviations should in theory be minor but point mutations may well be present in already in the P0 WT ZIKV sequenced in the study.

For alignment Bowtie2 was used with specified local alignment mode and the very sensitive default setting consisting of Qphred of 20, max number of mismatch of 0, length of seed substring 20, and interval between seed substrings S,1,0.5 to apply a stringent alignment. 

```{bash}
conda deactivate

# Activate sequencing environment
conda activate sequencing

# Make new directoies to facilitate bowtie2 output
mkdir test_data/QC_test_data/bowtie_index
mkdir test_data/QC_test_data/alignment

# Build index for reference genome
bowtie2-build -f WTZIKV_FSS13025_reference.fasta test_data/QC_test_data/bowtie_index/WTZIKV
```


```{bash}
# Run bowtie2 on both paired trimmed reads (-1 and -2) and on unpaired trimmed reads (-U)
bowtie2 --very-sensitive-local -x test_data/QC_test_data/bowtie_index/WTZIKV -1 test_data/QC_test_data/test_ERR4013290_1.trimmed.fastq -2 test_data/QC_test_data/test_ERR4013290_2.trimmed.fastq \
-U test_data/QC_test_data/test_ERR4013290_1un.trimmed.fastq, test_data/QC_test_data/test_ERR4013290_2un.trimmed.fastq \ -S test_data/QC_test_data/alignment/WTZKVIP0.sam 

bowtie2 --very-sensitive-local -x all_data/QC_all_data/WT_P1/bowtie_index/WTZIKV -1 all_data/QC_all_data/WT_P1/ERR4013299_1.trimmed.fastq -2 all_data/QC_all_data/WT_P1/ERR4013299_2.trimmed.fastq \
-U all_data/QC_all_data/WT_P1/ERR4013299_1un.trimmed.fastq, all_data/QC_all_data/WT_P1/ERR4013299_2un.trimmed.fastq \ -S all_data/QC_all_data/WT_P1/alignment/WTZKVIP1.sam 

>>>>>>> 403c3033675fa61f663d2488fb5e39b8eea8fbd5
```


# Compress SAM file and sort by coordinate
**Samtool view** and **SortSam** using:
**SAMtools v1.1** and **Picard-tools v1.128**

<<<<<<< HEAD
```{bash}
# Run picard on .bam file
picard SortSam \
      I=QC_all_data/10D_P0/alignment/10D_P0.bam \
      O=QC_all_data/10D_P0/alignment/10D_P0_sorted.bam \
      SORT_ORDER=coordinate
# View the sorted .bam file
samtools view QC_all_data/10D_P0/alignment/10D_P0_sorted.bam | less -S
```

Found this on GenBank for the wild type strain: https://www.ncbi.nlm.nih.gov/nuccore/MH158236.1

=======
Convert alignment .sam file to binary .bam format.
```{bash}
conda activate sequencing

# Convert using samtools view
samtools view -S -b test_data/QC_test_data/alignment/WTZKVIP0.sam > test_data/QC_test_data/alignment/WTZKVIP0.bam

```

```{bash}

# Install Picard
conda install -c bioconda picard

```

```{bash}

# Run picard on .bam file
picard SortSam \
      I=test_data/QC_test_data/alignment/WTZKVIP0.bam \
      O=test_data/QC_test_data/alignment/WTZKVIP0_sorted.bam \
      SORT_ORDER=coordinate

# View the sorted .bam file
samtools view test_data/QC_test_data/alignment/WTZKVIP0_sorted.bam | less -S
```

>>>>>>> 403c3033675fa61f663d2488fb5e39b8eea8fbd5

# Remove PCR duplicates
**MarkDuplicates** and **Picard-tools v1.128**
```{bash}
# Remove duplicates
picard MarkDuplicates \
      I=QC_all_data/10D_P0/alignment/10D_P0_sorted.bam \
      O=QC_all_data/10D_P0/alignment/10D_P0_sorted_removed_duplicates.bam \
      M=QC_all_data/10D_P0/alignment/10D_P0_sorted_removed_dup_metrics.txt \
      REMOVE_DUPLICATES=true
# View the data
samtools view QC_all_data/10D_P0/alignment/10D_P0_sorted_removed_duplicates.bam | less -S
```

Run picard MarkDuplicates on the sorted .bam file to remove PCR-duplicates. 

Left to do: Check the files before and after removal, what has changed? 

```{bash}
# Remove duplicates
picard MarkDuplicates \
      I=test_data/QC_test_data/alignment/WTZKVIP0_sorted.bam \
      O=test_data/QC_test_data/alignment/WTZKVIP0_sorted_removed_duplicates.bam \
      M=test_data/QC_test_data/alignment/WTZKVIP0_sorted_removed_dup_metrics.txt \
      REMOVE_DUPLICATES=true

# View the data
samtools view test_data/QC_test_data/alignment/WTZKVIP0_sorted_removed_duplicates.bam | less -S
```


# Variant detection
**V-phaser2 v2.0**

```{bash}
# Make a new directory for storing the Vphaser output
<<<<<<< HEAD
mkdir /home/student12/project/data/all_data/QC_all_data/10D_P0/variant_calling
conda activate sequencing
# Install Vphaser2
conda install -c bioconda vphaser2
```
```{bash}
# Run Vphaser2 on the duplicate removed, sorted file
vphaser2 -i QC_all_data/10D_P0/alignment/10D_P0_sorted_removed_duplicates.bam -o QC_all_data/10D_P0/variant_calling/10D_P0_SNP \          
variant_calling
```
=======
mkdir variant_calling

conda activate sequencing

# Install Vphaser2
conda install -c bioconda vphaser2

```


```{bash}

# Run Vphaser2 on the duplicate removed, sorted file
vphaser2 test_data/QC_test_data/alignment/WTZKVIP0_sorted_removed_duplicates.bam \
          variant_calling

```

>>>>>>> 403c3033675fa61f663d2488fb5e39b8eea8fbd5

# Shannon entropy
**RF** and **bam2R** using:
**deepSNV v1.16.0**

```{r}
new_entropy = function(x){
  x[1:5]
  new_entropy = -sum(x*log(x), na.rm = TRUE)
  
  return(new_entropy)}
```


############################### WT_P0 #######################################
```{bash}

mkdir /home/student12/project/data/all_data/QC_all_data/WT_P0



trimmomatic PE -threads 4 ERR4013290_1.fastq ERR4013290_2.fastq  \
              QC_all_data/WT_P0/ERR4013290_1.trimmed.fastq                         QC_all_data/WT_P0/ERR4013290_1un.trimmed.fastq \
              QC_all_data/WT_P0/ERR4013290_2.trimmed.fastq QC_all_data/WT_P0/ERR4013290_2un.trimmed.fastq \
              TRAILING:35 MINLEN:35
              
fastqc QC_all_data/WT_P0/ERR4013290_1.trimmed.fastq

mkdir /home/student12/project/data/all_data/QC_all_data/WT_P0/bowtie_index
mkdir /home/student12/project/data/all_data/QC_all_data/WT_P0/alignment

bowtie2-build -f WTZIKV_FSS13025_reference.fasta all_data/QC_all_data/WT_P0/bowtie_index/WTZIKV

bowtie2 --very-sensitive-local -x QC_all_data/WT_P0/bowtie_index/WTZIKV -1  QC_all_data/WT_P0/ERR4013290_1.trimmed.fastq -2 QC_all_data/WT_P0/ERR4013290_2.trimmed.fastq -U  QC_all_data/WT_P0/ERR4013290_1un.trimmed.fastq, QC_all_data/WT_P0/ERR4013290_2un.trimmed.fastq -S  QC_all_data/WT_P0/alignment/WT_P0.sam 

samtools view -S -b QC_all_data/WT_P0/alignment/WT_P0.sam > QC_all_data/WT_P0/alignment/WT_P0.bam  

picard SortSam \
      I=QC_all_data/WT_P0/alignment/WT_P0.bam \
      O=QC_all_data/WT_P0/alignment/WT_P0_sorted.bam \
      SORT_ORDER=coordinate

samtools view QC_all_data/WT_P0/alignment/WT_P0_sorted.bam | less -S

picard MarkDuplicates \
      I=QC_all_data/WT_P0/alignment/WT_P0_sorted.bam \
      O=QC_all_data/WT_P0/alignment/WT_P0_sorted_removed_duplicates.bam \
      M=QC_all_data/WT_P0/alignment/WT_P0_sorted_removed_dup_metrics.txt \
      REMOVE_DUPLICATES=true

samtools view QC_all_data/WT_P0/alignment/WT_P0_sorted_removed_duplicates.bam | less -S

vphaser2 -i QC_all_data/WT_P0/alignment/WT_P0_sorted_removed_duplicates.bam -o QC_all_data/WT_P0/variant_calling/WT_P0_SNP \          
variant_calling
            
```

