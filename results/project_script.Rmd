  
---
title: "Project outline"
#output: html_notebook
---

# Instructions
This script is written for a test data set and can be run from start (QC preprocessing) to finish (Shannon entropy calculation). The test data set is generated in the data_acquisition.Rmd script and consist of a pair-end read for WTZIKV P0. The script is written so that it is run with the data directory as its working directory.

# QC Preprocessing
- **Original study:** Trimmomatic v0.22
- **Reproduction:** Trimmomatic v0.39

The trimming and quality control is done by using the software Trimmomatic. The version in the article is v0.22, we will operate on the current release v0.39. Although not a part of the original study, we will download the fastQC software for simple data visualization before and after trimming. Trim to minimal 35 bases and 35 quality scor as per instructed in original study.

```{bash}
# Initiate conda
source ~/.bashrc
# create new conda environment
conda create --name project
# activate conda environment
conda activate project
# Check current packages
conda list
# Install packages
conda install -c bioconda trimmomatic
conda install -c bioconda fastqc
```

Run fastQC software to inspect data. This will generate a .fastqc.zip file and a .html file which can be opened in a browser through Rstudio. This will show basic statistics for the read, including its average quality score across reads.
```{bash}
fastqc test_data/test_ERR4013290_1.fastq
```

Trimming and quality control may now be performed using Trimmomatic v0.39. Make new QC directory to facilitate trimmomatic output.
```{bash}
mkdir test_data/QC_test_data
trimmomatic PE -threads 4 test_ERR4013290_1.fastq test_ERR4013290_2.fastq  \
QC_test_data/test_ERR4013290_1.trimmed.fastq QC_test_data/test_ERR4013290_1un.trimmed.fastq \
QC_test_data/test_ERR4013290_2.trimmed.fastq QC_test_data/test_ERR4013290_2un.trimmed.fastq \
TRAILING:35 MINLEN:35
```

Optional: run fastQC again to view the trimmed data.
```{bash}
fastqc test_data/QC_test_data/test_ERR4013290_1.trimmed.fastq
```

# *de novo* assembly
- **Original study:** ABySS v1.3.7
- **Reproduction:** ABySS v2.2.5

ABySS is an assembler intended for short read data, such as the data generated by Illumina machines. Here the latest version (ABySS v) is used with a k-mere length of 30 to assemble *de novo* consensus sequences from the quality controlled pair-end reads. Note: in the original study ABySS v1.3.7 with a range of k values from 20 to 40 was used to find a optimal k-mere length.
```{bash}
conda install -c bioconda abyss
```

Run ABySS on the quality trimmed data. Make new directory to facilitate the big output from ABySS. ABySS can be run with either only the remaining pairs that survived the trimming or both the pairs and the remaining single reads. The last option does not generate a contigs.fa file and is therefore in some way erroneous.
```{bash}
mkdir test_data/QC_test_data/abyss_pe
abyss-pe name=WTZIKA k=30 in="test_data/QC_test_data/test_ERR4013290_1.trimmed.fastq 
                              test_data/QC_test_data/test_ERR4013290_2.trimmed.fastq" 
                              
# Move files to folder
mv test_data/QC_test_data/WTZIKA* test_data/QC_test_data/abyss_pe
mv test_data/QC_test_data/coverage* test_data/QC_test_data/abyss_pe
# Alternitavely: also include the single reads "un paired", this is erroneous
mkdir test_data/QC_test_data/abyss_pe_se
abyss-pe name=WTZIKA k=30 pe="test_data/QC_test_data/test_ERR4013290_1.trimmed.fastq 
                              test_data/QC_test_data/test_ERR4013290_2.trimmed.fastq" \                                                                     se="test_data/QC_test_data/test_ERR4013290_1un.trimmed.fastq       
                              test_data/QC_test_data/test_ERR4013290_2un.trimmed.fastq" 
# Move files to folder
mv test_data/QC_test_data/WTZIKA* test_data/QC_test_data/abyss_pe_se
mv test_data/QC_test_data/coverage* test_data/QC_test_data/abyss_pe_se
```

The output from the assembly is not sufficient for aligning since it does not consist of a single string (a genome). Therefore, the *de novo* sequences are not used further. Moving directly from here to Alignment with the *de novo* sequences replaced by a reference genome instead for the wild type strain.

# SKIPPED: Disassembly BAM files
- **Original study:** SamToFastq.jar and SAMtools
This step is only used if the ABySS software runs successfully. Therefore, this is skipped in the reproduction.

# Alignment
- **Original study:** Bowtie2 v2.2.4
- **Reproduction:** Bowtie2 v2.4.2

A full genome for WT ZIKV, strain FSS13025, is downloaded from GenBank (https://www.ncbi.nlm.nih.gov/nuccore/MH158236.1) to be used as reference sequence for alignment. This is done instead of using the failed *de novo* sequence generated by ABySS. The deviations should in theory be minor but point mutations may well be present in already in the P0 WT ZIKV sequenced.

For alignment Bowtie2 is used with specified local alignment mode and the very sensitive default setting consisting of Qphred of 20, max number of mismatch of 0, length of seed substring 20, and interval between seed substrings S,1,0.5 to apply a stringent alignment, as per instructed in original study. 

Bowtie2 uses a different version of python than the one used by trimmomatic, therefore, another conda environment is used for the following downstream analysis.

```{bash}
conda deactivate
# Create new environment
conda create --name project_downstream
conda activate project_downstream
# Install Bowtie2
conda install bowtie2
```

Make new directories to facilitate bowtie alignment as well as the generated bowtie index.
```{bash}
mkdir test_data/QC_test_data/bowtie_index
mkdir test_data/QC_test_data/alignment
# Build index for reference genome
bowtie2-build -f WTZIKV_FSS13025_reference.fasta test_data/QC_test_data/bowtie_index/WTZIKV
```

Run bowtie2 on the quality trimmed data.
```{bash}
# Run bowtie2 on both paired trimmed reads (-1 and -2) and on unpaired trimmed reads (-U)
bowtie2 --very-sensitive-local -x \
test_data/QC_test_data/bowtie_index/WTZIKV \
-1 test_data/QC_test_data/test_ERR4013290_1.trimmed.fastq \
-2 test_data/QC_test_data/test_ERR4013290_2.trimmed.fastq \
-U test_data/QC_test_data/test_ERR4013290_1un.trimmed.fastq, test_data/QC_test_data/test_ERR4013290_2un.trimmed.fastq \
-S test_data/QC_test_data/alignment/WTZKVIP0.sam 
```


# Compress SAM file and sort by coordinate
- **Original study:** SAMtools v1.1
- **Original study:** Picard-tools v1.128
- **Reproduction:** SAMtools v1.11
- **Reproduction:** Picard-tools v2.18.7

Install packages using conda. These are neccessary to convert the alignment .sam file from bowtie2 to a binary format (.bam) and to sort the .bam file by coordinate in the genome. This in turn is neccessary in order to find duplicates from the PCR amplification later and for calling SNPs. 
```{bash}
conda install -c bioconda samtools
conda install -c bioconda picard
```

Convert alignment .sam file to binary .bam format.
```{bash}
# Convert using samtools view
samtools view -S -b test_data/QC_test_data/alignment/WTZKVIP0.sam > test_data/QC_test_data/alignment/WTZKVIP0.bam
```

Sort the .bam file by coordinate and view it by converting to .sam format using samtools. 
```{bash}
# Run picard on .bam file
picard SortSam \
      I=test_data/QC_test_data/alignment/WTZKVIP0.bam \
      O=test_data/QC_test_data/alignment/WTZKVIP0_sorted.bam \
      SORT_ORDER=coordinate
      
# View the sorted .bam file
samtools view test_data/QC_test_data/alignment/WTZKVIP0_sorted.bam | less -S
```

# Remove PCR duplicates
The next step is to remove the PCR duplicates from the amplification step before sequencing. This is done also using Picard with the function MarkDuplicates on the sorted .bam file. Choose the setting REMOVE_DUPLICATES to actually remove them, otherwise they will only be tagged. View the data again with samtools.
```{bash}
# Remove duplicates
picard MarkDuplicates \
      I=test_data/QC_test_data/alignment/WTZKVIP0_sorted.bam \
      O=test_data/QC_test_data/alignment/WTZKVIP0_sorted_removed_duplicates.bam \
      M=test_data/QC_test_data/alignment/WTZKVIP0_sorted_removed_dup_metrics.txt \
      REMOVE_DUPLICATES=true
      
# View the data
samtools view test_data/QC_test_data/alignment/WTZKVIP0_sorted_removed_duplicates.bam | less -S
```

# Variant detection
- **Original study:** V-phaser2 v2.0
- **Reproduciton:** V-phaser2 v2.0

This will aim to find all SNP:s present in the data. The software used is called V-phaser2 and finds potential SNP:s and their corresponding p-values. The p-values are corrected for FDR directly by the software.
```{bash}
# Make a new directory for storing the Vphaser output
mkdir test_data/QC_test_data/alignment/variant_calling
# Install Vphaser2
conda install -c bioconda vphaser2
```

Run V-phaser2 on the duplictate removed sorted .bam file.
```{bash}
# Run Vphaser2 on the duplicate removed, sorted file
vphaser2 -i test_data/QC_test_data/alignment/WTZKVIP0_sorted_removed_duplicates.bam \
          -o test_data/QC_test-data/alignment/variant_calling
```

# Shannon entropy
- **Original study:** deepSNV v1.16.0
- **Reproduction:** deepSNV v1.99.3

The Shannon entropy is calculated based on relative frequencies of nucleotides on each position in the genome. The frequencies are calculated using two functions in the R-package deepSNV, namely bam2R and RF. bam2R converts the duplicate removed, sorted .bam file to a count matrix with position in genome as rows and nucleotide/indel/quality as columns. The count matrix can be used inside the function RF to calculate each position's relative nucleotide frequency.

Install deepSNV into R. Note: The R version of the reproduction is 3.6 and does not support the current release of Bioconductor, therefore, an older version is installed.
```{r}
if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
BiocManager::install(version = "3.10")
# Install deepSNV
BiocManager::install("deepSNV")
```

Run bam2R to produce count matrix. Run from start position 107 to position 10700 and quality threshold 30, as per instructed by original study.
```{r}
library(deepSNV)
# Define path to file
path_to_file = "/home/student12/project/data/test_data/QC_test_data/alignment/"
# No chromosome available, pass empty string as argument
counts = bam2R(paste0(path_to_file, "WTZKVIP0_sorted_removed_duplicates.bam"), chr = "", start = 107, stop = 10700, q = 30)
```

Run RF to extract relative frequencies from count matrix. Extract the columns containing nucleotide information.
```{r}
# Extract columns with nucleotides (exclude N/n, INS/ins, DEL/del and QUAL/qual)
nucleotide_counts = counts[,c(1:5,12:16)]
# Run RF
relative_frequencies = RF(nucleotide_counts)
```

Calculate Shannon entropy from relative frequencies for each position in the genome. Note: original study only use the five first columns to calculate the entropy, not the last five. 
```{r}
# Function supplied by supplementary material of original study
new_entropy = function(x){
  x[1:5]
  new_entropy = -sum(x*log(x), na.rm = TRUE)
  
  return(new_entropy)}
# Convert to data.frame for visualization
shannon_entropy = as.data.frame(apply(relative_frequencies, 1, new_entropy))
```

# Save results
**V-phaser2 output**

Copy the file containing information about the SNP:s. Take the file that has been controlled for FDR with suffix .fdr.var.txt.
```{bash}
# Make new directory in results for storing all SNPs
mkdir /home/student12/project/results/SNP
# Find the file in the data directory and copy it to the new folder
cp `find test_data/QC_test_data/alignment/variant_calling -type f -name "*.fdr.var.txt"` /home/student12/project/results/SNP/test_SNP_WT_P0.fdr.var.txt
```


**Shannon entropy**

Make a new directory for saving the shannon entropies.
```{bash}
mkdir /home/student12/project/results/shannon_entropy
```

Save the Shannon entropy data.frame.
```{r}
path_to_save = "/home/student12/project/results/shannon_entropy/"
shannon_file_name = "test_WT_P0.txt"
write.table(shannon_entropy, paste0(path_to_save, shannon_file_name))
```




############################### WT_P0 #######################################
```{bash}
mkdir /home/student12/project/data/all_data/QC_all_data/WT_P0
trimmomatic PE -threads 4 ERR4013290_1.fastq ERR4013290_2.fastq  \
              QC_all_data/WT_P0/ERR4013290_1.trimmed.fastq                         QC_all_data/WT_P0/ERR4013290_1un.trimmed.fastq \
              QC_all_data/WT_P0/ERR4013290_2.trimmed.fastq QC_all_data/WT_P0/ERR4013290_2un.trimmed.fastq \
              TRAILING:35 MINLEN:35
              
fastqc QC_all_data/WT_P0/ERR4013290_1.trimmed.fastq
mkdir /home/student12/project/data/all_data/QC_all_data/WT_P0/bowtie_index
mkdir /home/student12/project/data/all_data/QC_all_data/WT_P0/alignment
bowtie2-build -f WTZIKV_FSS13025_reference.fasta all_data/QC_all_data/WT_P0/bowtie_index/WTZIKV
bowtie2 --very-sensitive-local -x QC_all_data/WT_P0/bowtie_index/WTZIKV -1  QC_all_data/WT_P0/ERR4013290_1.trimmed.fastq -2 QC_all_data/WT_P0/ERR4013290_2.trimmed.fastq -U  QC_all_data/WT_P0/ERR4013290_1un.trimmed.fastq, QC_all_data/WT_P0/ERR4013290_2un.trimmed.fastq -S  QC_all_data/WT_P0/alignment/WT_P0.sam 
samtools view -S -b QC_all_data/WT_P0/alignment/WT_P0.sam > QC_all_data/WT_P0/alignment/WT_P0.bam  
picard SortSam \
      I=QC_all_data/WT_P0/alignment/WT_P0.bam \
      O=QC_all_data/WT_P0/alignment/WT_P0_sorted.bam \
      SORT_ORDER=coordinate
samtools view QC_all_data/WT_P0/alignment/WT_P0_sorted.bam | less -S
picard MarkDuplicates \
      I=QC_all_data/WT_P0/alignment/WT_P0_sorted.bam \
      O=QC_all_data/WT_P0/alignment/WT_P0_sorted_removed_duplicates.bam \
      M=QC_all_data/WT_P0/alignment/WT_P0_sorted_removed_dup_metrics.txt \
      REMOVE_DUPLICATES=true
samtools view QC_all_data/WT_P0/alignment/WT_P0_sorted_removed_duplicates.bam | less -S
vphaser2 -i QC_all_data/WT_P0/alignment/WT_P0_sorted_removed_duplicates.bam -o QC_all_data/WT_P0/variant_calling/WT_P0_SNP \          
variant_calling
            
```




############################### 10D_P0 #######################################
```{bash}
mkdir /home/student12/project/data/all_data/QC_all_data/10D_P3

trimmomatic PE -threads 4 ERR4013304_1.fastq ERR4013304_2.fastq  \
              QC_all_data/10D_P3/ERR4013304_1.trimmed.fastq                         QC_all_data/10D_P3/ERR4013304_1un.trimmed.fastq \
              QC_all_data/10D_P3/ERR4013304_2.trimmed.fastq QC_all_data/10D_P3/ERR4013304_2un.trimmed.fastq \
              TRAILING:35 MINLEN:35
              
fastqc QC_all_data/10D_P3/ERR4013304_1.trimmed.fastq
mkdir /home/student12/project/data/all_data/QC_all_data/10D_P3/bowtie_index
mkdir /home/student12/project/data/all_data/QC_all_data/10D_P3/alignment
bowtie2-build -f WTZIKV_FSS13025_reference.fasta all_data/QC_all_data/10D_P3/bowtie_index/WTZIKV
bowtie2 --very-sensitive-local -x QC_all_data/10D_P3/bowtie_index/WTZIKV -1  QC_all_data/10D_P3/ERR4013304_1.trimmed.fastq -2 QC_all_data/10D_P3/ERR4013304_2.trimmed.fastq -U  QC_all_data/10D_P3/ERR4013304_1un.trimmed.fastq, QC_all_data/10D_P3/ERR4013304_2un.trimmed.fastq -S  QC_all_data/10D_P3/alignment/10D_P3.sam 
samtools view -S -b QC_all_data/10D_P3/alignment/10D_P3.sam > QC_all_data/10D_P3/alignment/10D_P3.bam  
picard SortSam \
      I=QC_all_data/10D_P3/alignment/10D_P3.bam \
      O=QC_all_data/10D_P3/alignment/10D_P3_sorted.bam \
      SORT_ORDER=coordinate
samtools view QC_all_data/10D_P3/alignment/10D_P3_sorted.bam | less -S
picard MarkDuplicates \
      I=QC_all_data/10D_P3/alignment/10D_P3_sorted.bam \
      O=QC_all_data/10D_P3/alignment/10D_P3_sorted_removed_duplicates.bam \
      M=QC_all_data/10D_P3/alignment/10D_P3_sorted_removed_dup_metrics.txt \
      REMOVE_DUPLICATES=true
samtools view QC_all_data/10D_P3/alignment/10D_P3_sorted_removed_duplicates.bam | less -S


mkdir /home/student12/project/data/all_data/QC_all_data/10D_P3/alignment/variant_calling

vphaser2 -i /home/student12/project/data/all_data/QC_all_data/10D_P3/alignment/10D_P3_sorted_removed_duplicates.bam -o /home/student12/project/data/all_data/QC_all_data/10D_P3/alignment/variant_calling


```

```{r}
if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
BiocManager::install(version = "3.10")
# Install deepSNV
BiocManager::install("Rsamtools")
BiocManager::install("VariantAnnotation")
BiocManager::install("deepSNV")
```
```{r}

library(deepSNV)
path_to_file = "/home/student12/project/data/all_data/QC_all_data/10D_P3/alignment/"
counts = bam2R(paste0(path_to_file, "10D_P3_sorted_removed_duplicates.bam"), chr = "", start = 107, stop = 10700, q = 30)

nucleotide_counts = counts[,c(1:5,12:16)]
relative_frequencies = RF(nucleotide_counts)
new_entropy = function(x){
  x[1:5]
  new_entropy = -sum(x*log(x), na.rm = TRUE)
  
  return(new_entropy)}

shannon_entropy = as.data.frame(apply(relative_frequencies, 1, new_entropy))
```
```{bash}

cp `find all_data/QC_all_data/10D_P3/alignment/variant_calling -type f -name "*.fdr.var.txt"` /home/student12/project/results/SNP/SNP_10D_P3.fdr.var.txt
```
```{r}
path_to_save = "/home/student12/project/results/shannon_entropy/"
shannon_file_name = "10D_P3.txt"
write.table(shannon_entropy, paste0(path_to_save, shannon_file_name))
```


