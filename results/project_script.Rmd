---
title: "R Notebook"
#output: html_notebook
---

# Loading data
## Load data into R
```{r}
# set root directory
root = "/home/student12/project/"

# Load the metadata, use paste0() to concatenate two strings
sample_metadata <- read_tsv(paste0(root,"data/sample_metadata.txt"))

# inspect metadata
head(sample_metadata)
```

# QC Preprocessing
Trim to minimal 35 bases and 35 quality score: **Trimmomatic v0.22**

## Packages and software
The trimming and quality control is done by using the software Trimmomatic. The version in the article is v0.22, we will operate on the current release v0.39. Although not a part of the original study, we will download the fastQC software for simple data visualization before and after trimming.

```{bash}
# Initiate conda
source ~/.bashrc

# activate conda environment
conda activate project

# The project environment is a clone of the sequencing conda environment containing:
# conda install samtools bowtie2 breseq abyss bcftools wgsim emboss tree

conda install -c bioconda trimmomatic

# Not mandatory: install fastqc to view fastq files in browser
conda install -c bioconda fastqc

```

Run fastQC software to inspect data. This will generate a .fastqc.zip file and a .html file which can be opened in a browser through Rstudio. This will show basic statistics for the read, including its average quality score across reads.

```{bash}
fastqc test_data/TEST_FILE
```


## Trimming and quality control
Trimming and quality control may now be performed using Trimmomatic v0.39. 

```{bash}
mkdir QC_test_data

trimmomatic PE -threads 4 test_ERR4013290_1.fastq test_ERR4013290_2.fastq  \
              QC_test_data/test_ERR4013290_1.trimmed.fastq                         QC_test_data/test_ERR4013290_1un.trimmed.fastq \
              QC_test_data/test_ERR4013290_2.trimmed.fastq QC_test_data/test_ERR4013290_2un.trimmed.fastq \
              TRAILING:35 MINLEN:35

```

# de novo assembly
**ABySS v1.3.7**
ABySS v1.3.7 with k values from 20 to 40 was used for de novo assembly of pair-end reads and de novo consensus sequences generated.

```{bash}
# Install ABySS using conda
conda install -c bioconda abyss
```

Run ABySS
```{bash}
mkdir abyss_pe

abyss-pe name=WTZIKA k=20 in="test_ERR4013290_1.trimmed.fastq 
                              test_ERR4013290_2.trimmed.fastq" 
                              
# Move files to folder
mv WTZIKA* abyss_pe
mv coverage* abyss_pe

mkdir abyss_pe_se

abyss-pe name=WTZIKA k=20 pe="test_ERR4013290_1.trimmed.fastq test_ERR4013290_2.trimmed.fastq"                              se="test_ERR4013290_1un.trimmed.fastq test_ERR4013290_2un.trimmed.fastq" 
mv WTZIKA* abyss_pe_se
mv coverage* abyss_pe_se
```

Questions for Sandra: ABySS takes super long to run +2h for each pair. How can we automate it? 
                      de novo concensus, what are the contigs?
                      What do they mean in the protocol, first aligning to the de novo assembly                         but also aligning to a reference?


```{r}

```

# Disassembly BAM files
**SamToFastq.jar** and **SAMtools**


# Alignment
(reference, de novo concensus) with very sensitive local alignment:
**Bowtie2 v2.2.4**

Found this on GenBank for the wild type strain: https://www.ncbi.nlm.nih.gov/nuccore/MH158236.1


# Compress SAM file and sort by coordinate
**Samtool view** and **SortSam** using:
**SAMtools v1.1** and **Picard-tools v1.128**


# Remove PCR duplicates
**MarkDuplicates** and **Picard-tools v1.128**


# Variant detection
**V-phaser2 v2.0**


# Shannon entropy
**RF** and **bam2R** using:
**deepSNV v1.16.0**

```{r}
new_entropy = function(x){
  x[1:5]
  new_entropy = -sum(x*log(x), na.rm = TRUE)
  
  return(new_entropy)}
```


